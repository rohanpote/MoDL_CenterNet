{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(sys.path[0]+'/../lib') # Add library folder\n",
    "#print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opts import opts\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from datasets.dataset.coco import COCO\n",
    "from datasets.sample.ctdet import CTDetDataset\n",
    "from trains.ctdet import CtdetTrainer\n",
    "from trains.train_factory import train_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = get_dataset('coco', 'ctdet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(sys.path[0]+'/../project_tools')\n",
    "from fcn_opts import fcn_opts\n",
    "opt = fcn_opts(Dataset)\n",
    "opt.reg_loss = 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create opt for passing to the constructor. \\\n",
    "Also pass a string with the training value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> initializing coco 2017 train data.\n",
      "loading annotations into memory...\n",
      "Done (t=20.69s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded train 118287 samples\n",
      "==> initializing coco 2017 val data.\n",
      "loading annotations into memory...\n",
      "Done (t=0.84s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded val 5000 samples\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(opt,'train')\n",
    "valset = Dataset(opt, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initial testing we are modifying the dataset to a smaller size. The following code updates the json file list to use a smalller subset of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118287\n"
     ]
    }
   ],
   "source": [
    "all_Ids=dataset.coco.getImgIds()\n",
    "all_Ids2=valset.coco.getImgIds()\n",
    "print(len(all_Ids))\n",
    "import skimage.io as io\n",
    "img_dir='~/MoDL_CenterNet/data/coco/train2017/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=512\n",
    "import random\n",
    "np.random.seed(0)\n",
    "numsets=1\n",
    "for iter in range(numsets):\n",
    "    imgIds_perm=np.random.permutation(len(all_Ids2))\n",
    "    tmp=imgIds_perm[0:M].astype(int)\n",
    "    tmp2=[all_Ids2[t] for t in tmp]\n",
    "    valset.images=tmp2\n",
    "    valset.num_samples=len(valset.images)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N=2048\n",
    "import random\n",
    "np.random.seed(0)\n",
    "numsets=1\n",
    "for iter in range(numsets):\n",
    "    imgIds_perm=np.random.permutation(len(all_Ids))\n",
    "    tmp=imgIds_perm[0:N].astype(int)\n",
    "    tmp2=[all_Ids[t] for t in tmp]\n",
    "    dataset.images=tmp2\n",
    "    dataset.num_samples=len(dataset.images)\n",
    "    sub_inst_cat=np.zeros(90)\n",
    "    for j in range(N):\n",
    "        sub_cat_lab=[]\n",
    "        img = dataset.coco.loadImgs(dataset.images[j])[0]\n",
    "        f_name=img_dir\n",
    "        f_name+=img['file_name']\n",
    "        annIds = dataset.coco.getAnnIds(imgIds=img['id'])\n",
    "        anns = dataset.coco.loadAnns(annIds)\n",
    "        sub_cat_lab=[k['category_id'] for k in anns]\n",
    "        for jj in range(90):\n",
    "            t=np.where(np.asarray(sub_cat_lab)==jj)\n",
    "            sub_inst_cat[jj-1]+=t[0].shape[0]\n",
    "    prob_sub=(sub_inst_cat+1)/np.sum(sub_inst_cat+1)    \n",
    "    plt.plot(sub_inst_cat/(np.sum(sub_inst_cat)))\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 3, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.num_iters = dataset.num_samples/opt.batch_size\n",
    "#print(dataset.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(sys.path[0]+'/../lib/models/networks/DCNv2')\n",
    "from models.model import create_model, load_model, save_model\n",
    "from trains.ctdet import CtdetTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading pretrained model https://download.pytorch.org/models/resnet18-5c106cde.pth\n",
      "=> init deconv weights from normal distribution\n"
     ]
    }
   ],
   "source": [
    "# regression on center point.\n",
    "model = create_model(opt.arch, opt.heads, opt.head_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), opt.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centernet_model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(sys.path[0]+\"/../project_tools\")\n",
    "import nntools as nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Centernet_model(nt.NeuralNetwork,CtdetTrainer):\n",
    "    def __init__(self,opt,model,optimizer=None,FineTune=True):\n",
    "        nt.NeuralNetwork.__init__(self)\n",
    "        CtdetTrainer.__init__(self,opt,model,optimizer=None)\n",
    "        if FineTune:\n",
    "            for name,param in model.named_parameters():\n",
    "               if name[0:2]=='hm' or name[0:2]=='re' or name[0:2]=='wh':\n",
    "                    param.data = 1e-1*torch.randn(param.size()) # Random initialization\n",
    "               else: \n",
    "                    param.requires_grad=False\n",
    "            #print(name,param.requires_grad)\n",
    "        self.model=model\n",
    "        self.model_with_loss.model = model\n",
    "        self.opt=opt\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    def criterion(self, y, d):\n",
    "        return self.loss(y,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CtdetTrainer(opt, model, optimizer)\n",
    "trainer.set_device(opt.gpus, opt.chunk_sizes, opt.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded /datasets/home/home-01/27/827/ausant/ECE285Project/MoDL_CenterNet/src/local_notebooks/../../models/ctdet_coco_resdcn18.pth, epoch 140\n"
     ]
    }
   ],
   "source": [
    "model =load_model(model,sys.path[0]+'/../../models/ctdet_coco_resdcn18.pth');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for name,param in net.model.named_parameters():\n",
    "#    print(name,param.size(),param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Change Regularization Loss to $l_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CtdetTrainer(opt, model, optimizer)\n",
    "trainer.set_device(opt.gpus, opt.chunk_sizes, opt.device)\n",
    "net_mse = Centernet_model(opt,model);\n",
    "net_mse = net_mse.to(opt.device)\n",
    "adam = torch.optim.Adam(net_mse.parameters(), lr=opt.lr)\n",
    "stats_manager = nt.StatsManager()\n",
    "exp_reg_loss_mse = nt.Experiment(net_mse,dataset,valset,adam,stats_manager,\n",
    "output_dir=\"Experiment_RegLoss_l2_2000_samples1\", batch_size=opt.batch_size,perform_validation_during_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start/Continue training from epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (512) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-578658ec1df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp_reg_loss_mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/datasets/home/home-01/27/827/ausant/ECE285Project/MoDL_CenterNet/src/local_notebooks/../project_tools/nntools.py\u001b[0m in \u001b[0;36mrun2\u001b[0;34m(self, num_epochs, plot)\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-1356f4993e61>\u001b[0m in \u001b[0;36mcriterion\u001b[0;34m(self, y, d)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/27/827/ausant/ECE285Project/MoDL_CenterNet/src/local_notebooks/../lib/trains/ctdet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, batch)\u001b[0m\n\u001b[1;32m     48\u001b[0m           output['reg'].shape[3], output['reg'].shape[2])).to(opt.device)\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0mhm_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_stacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwh_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_wh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/27/827/ausant/ECE285Project/MoDL_CenterNet/src/local_notebooks/../lib/models/losses.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, out, target)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRegLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/datasets/home/home-01/27/827/ausant/ECE285Project/MoDL_CenterNet/src/local_notebooks/../lib/models/losses.py\u001b[0m in \u001b[0;36m_neg_loss\u001b[0;34m(pred, gt)\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpos_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpos_inds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0mneg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mneg_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mneg_inds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (512) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "exp_reg_loss_mse.run2(num_epochs=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(exp_reg_loss_mse.history,label='MSE Reg Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_reg_loss_mse.history[174]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_reg_loss_mse.evaluate2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Basic Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt.task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Detector object: Loads model from their library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(sys.path[0]+'/../lib/models/networks/DCNv2')\n",
    "opt.K = 100\n",
    "opt.vis_thresh = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectors.ctdet import CtdetDetector\n",
    "opt.load_model = sys.path[0]+'/../../models/ctdet_coco_resdcn18.pth'\n",
    "Detector = CtdetDetector(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwrite with the model saved in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "our_model = exp_reg_loss_mse.net.model\n",
    "Detector.model = our_model\n",
    "Detector.model = Detector.model.to(opt.device)\n",
    "Detector.model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = Dataset(opt, 'val')\n",
    "all_Ids3=testset.coco.getImgIds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main for loop to test one image at a time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.save_dir = sys.path[0]+'/Experiment_RegLoss_l2_2000_samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "num_iters = testset.num_samples\n",
    "for ind in range(num_iters):\n",
    "    if(np.mod(ind,100)==0):\n",
    "        print(ind)\n",
    "    img_id = testset.images[ind]\n",
    "    img_info = testset.coco.loadImgs(ids=[img_id])[0]\n",
    "    img_path = os.path.join(testset.img_dir, img_info['file_name'])\n",
    "    ret = Detector.run(img_path)\n",
    "    results[img_id] = ret['results']\n",
    "    \n",
    "#print(sum([ret['results'][i+1].shape[0] for i in range(80)]))\n",
    "#print([(ret['results'][i+1].shape[0],i+1) for i in range(80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.run_eval(results, opt.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=40\n",
    "opt.nms = True\n",
    "np.random.seed(16)\n",
    "numsets=1\n",
    "for iter in range(numsets):\n",
    "    imgIds_perm=np.random.permutation(len(all_Ids3))\n",
    "    tmp=imgIds_perm[0:P].astype(int)\n",
    "    tmp2=[all_Ids3[t] for t in tmp]\n",
    "    testset.images=tmp2\n",
    "    testset.num_samples=len(testset.images)\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "num_iters = testset.num_samples\n",
    "for ind in range(num_iters):\n",
    "    if(np.mod(ind,100)==0):\n",
    "        print(ind)\n",
    "    img_id = testset.images[ind]\n",
    "    img_info = testset.coco.loadImgs(ids=[img_id])[0]\n",
    "    img_path = os.path.join(testset.img_dir, img_info['file_name'])\n",
    "    ret = Detector.run(img_path)\n",
    "    results[img_id] = ret['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import skimage.io as io\n",
    "img_dir=sys.path[0]+'/../../data/coco/val2017/'\n",
    "#num_cols = 1\n",
    "#fig, axes = plt.subplots(ncols=num_cols, nrows=int(P/num_cols), figsize=(20,300))\n",
    "show_txt = True\n",
    "\n",
    "coco_class_name = [\n",
    "     'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "     'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
    "     'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
    "     'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack',\n",
    "     'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
    "     'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "     'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass',\n",
    "     'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "     'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
    "     'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "     'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "     'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "     'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "num_iters = testset.num_samples\n",
    "\n",
    "\n",
    "for ind in range(num_iters):\n",
    "    img_id = testset.images[ind]\n",
    "    im_id = img_id\n",
    "    img = testset.coco.loadImgs(im_id)[0]\n",
    "    f_name=img_dir\n",
    "    f_name+=img['file_name']\n",
    "    I = io.imread(f_name)\n",
    "    for c_id in range(80):\n",
    "        for j in range(results[img_id][c_id+1].shape[0]):\n",
    "            if results[img_id][c_id+1][j][4]>=opt.vis_thresh*2/3:\n",
    "                bbox = results[img_id][c_id+1][j]\n",
    "                cv2.rectangle(I, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0,255,0), 2)\n",
    "                if show_txt:\n",
    "                    txt = '{}{:.1f}'.format(coco_class_name[c_id], bbox[4]) # text+confidence\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    cat_size = cv2.getTextSize(txt, font, 0.5, 2)[0]\n",
    "                    cv2.rectangle(I, (bbox[0], int(bbox[1] - cat_size[1] - 2)),\n",
    "                                  (int(bbox[0] + cat_size[0]), int(bbox[1] - 2)), (0,255,0), -1)\n",
    "                    cv2.putText(I, txt, (bbox[0], int(bbox[1] - 2)), \n",
    "                                font, 0.5, (0, 0, 0),thickness=1, lineType=cv2.LINE_AA)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
