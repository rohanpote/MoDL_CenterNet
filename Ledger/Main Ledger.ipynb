{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ledger contains all updates to the project. It includes important code snippets, information, explantion, references and other relavant information for all collaborators. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date: 11/17/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inital setup\n",
    "* Created ledger\n",
    "* Created git repository\n",
    "* Shifted ledger to git "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added nntools.py to folder src\n",
    "* Use to inherit Experiment and other class funtionalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a new folder: local_tools\n",
    "* This folder contains all the custom libraries and classes that we write\n",
    "* Shifted nntools.py to this folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a new folder: local_notebooks\n",
    "* This folder used to create different local python notebooks for each colaborators\n",
    "* Any changes to functions can be added here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command to download a file (e.g. a model) from Google Drive\n",
    "\n",
    "wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O FILENAME\n",
    "\n",
    "E.g: wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1b-_sjq1Pe_dVxt5SeFmoadMfiPTPZqpz' -O ctdet_coco_resdcn18.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make external\n",
    "~/MoDL_CenterNet/src/lib/external$ make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCNv2 for Pytorch 1.0\n",
    "Repo: https://github.com/CharlesShang/DCNv2 (clone in MoDL_CenterNet/src/lib/models/networks/DCNv2/)\n",
    "\n",
    "python setup.py build  # build\n",
    "\n",
    "PYTHONPATH=\"${PYTHONPATH}:path_until_here/MoDL_CenterNet/src/lib/models/networks/DCNv2\"\n",
    "\n",
    "export PYTHONPATH\n",
    "\n",
    "python setup.py develop --instal-dir path_until_here/MoDL_CenterNet/src/lib/models/networks/DCNv2 #install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Test script error on unable to find model\n",
    "Copy the model to MoDL_CenterNet/exp/ctdet/model_name and rename to 'model_last.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date: 11/23/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added a local notebook to read data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating custom object opt with desired parameters just sufficient to call the class COCO\n",
    "* This class can be used to execute the cocoapi toolkit to manipulate the images on the Jupyter notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts of the local notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This describes the different parts of the notebook that have been added. The goal is to run the same script in the library without the need for command line arguments. This also gives us complete control over the parameters of interest and will be benefitial for future modifications of the network. \n",
    "\n",
    "The empty object opt is created and then each individual feature of this object is updated based on our requirement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original opt object is initialized using the command line argument, when calling the main script. The aim here is to pass all these parameters to the object through the notebook. \n",
    "* opt is initialized as an empty object\n",
    "* All experimental parameters, loss, data and image parameters\n",
    "* The different directories for storing the model, epochs and data is stored in this object\n",
    "* This can be used for any further modifications to the program "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is the MS COCO 2017 dataset. The data is loaded in the user directory root folder. \n",
    "\n",
    "The dataset can be manipulate using the cocoapi libraries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For initial testing we are modifying the dataset to a smaller size. The following code updates the json file list to use a smalller subset of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=256\n",
    "numsets=1\n",
    "for iter in range(numsets):\n",
    "    imgIds_perm=np.random.permutation(len(all_Ids))\n",
    "    tmp=imgIds_perm[0:N].astype(int)\n",
    "    tmp2=[all_Ids[t] for t in tmp]\n",
    "    dataset.images=tmp2\n",
    "    dataset.num_samples=len(dataset.images)\n",
    "    sub_inst_cat=np.zeros(90)\n",
    "    for j in range(N):\n",
    "        sub_cat_lab=[]\n",
    "        img = dataset.coco.loadImgs(dataset.images[j])[0]\n",
    "        f_name=img_dir\n",
    "        f_name+=img['file_name']\n",
    "        annIds = dataset.coco.getAnnIds(imgIds=img['id'])\n",
    "        anns = dataset.coco.loadAnns(annIds)\n",
    "        sub_cat_lab=[k['category_id'] for k in anns]\n",
    "        for jj in range(90):\n",
    "            t=np.where(np.asarray(sub_cat_lab)==jj)\n",
    "            sub_inst_cat[jj-1]+=t[0].shape[0]\n",
    "    prob_sub=(sub_inst_cat+1)/np.sum(sub_inst_cat+1)    \n",
    "    plt.plot(sub_inst_cat/(np.sum(sub_inst_cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this script, it is possible to proivide the statistics of the smaller dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given framework is decided to acoomodate different achitectures for object classification. The models relevant for the COCO dataset are: \n",
    "* Renet18\n",
    "* Resnet 101\n",
    "* DLA\n",
    "* Hourglass\n",
    "\n",
    "The original literature/libraries provide separate python scripts for loasing these models. For the inital testing and validation the Resnet 18 architechture was used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainer object type contains the structure for training different architectures with different loss functions. There are 2 major modules used here, for the task of object classification: \n",
    "* BaseTrainer\n",
    "    * This class contains the stensil functionality for the loss, optimizer and model characteristics, not specifying them \n",
    "    * The forward and training functionality is defined by this class, executed during each epoch\n",
    "    * The individual trainers are given specifc to each class\n",
    "* CtdetTrainer\n",
    "    * This inherits the main base trainer functionality and defines the losses specific to object detection and classification\n",
    "    * In addition this module also contains the debugger for the trainer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the main loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial loop test was run on a subset of the data, with a single epoch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date: 11/27/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining trainer and running functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original functionality of the of the CenterNet framework was as follows: \n",
    "* Model creation\n",
    "    * Imports existing architecture from the presaved pytorch modules (Resnet18 for this case)\n",
    "    * Adds dcnV2 functionality to the model\n",
    "    * The object only has attributes about the architecture; it is independent of the loss and forward propogation\n",
    "* Trainer: Ctdet trainer object\n",
    "    * Inherits the BaseTrainer class object with features for losses, training and saving at the end of the epochs\n",
    "    * Requires the model, optimizer and opt parameters passed as arguments during object assignment\n",
    "    * trainer.model_with_loss object:\n",
    "        * Has attribute model, that forward propagates the batch input and returns the output\n",
    "        * Has attribute loss (Ctdet loss class), which contains the loss calculation in its forward() definition\n",
    "* Running epoch\n",
    "    * The trainer set in 'train' mode and batch is passed\n",
    "    * model_with_loss object is called \n",
    "        * Computes the output using the forward of trainer.model\n",
    "        * computes loss using the forward of the CtDet loss class\n",
    "    * loss.mean() computed for avg batch loss\n",
    "    * loss.backward() does the backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This structure is designed by the original authors for flexibility of executing architectures and losses. It is desired to execute the entire framework, in a single class Centernet_Model that does the forard as well as the backpropagation. \n",
    "* The model creation is left as is and passed to the Centernet_model while calling the constructor\n",
    "* Inherits classes nt.NeuralNetwork and CtdetTrainer \n",
    "* The constructor definition\n",
    "    * Initialize both the parent classes\n",
    "    * Set attribute self.model as model\n",
    "    * Set the features that are not to be trained to False\n",
    "* forward() function is used to calculate the outputs, using the the forward defintion of self.model\n",
    "* criterion() is used to set the attribute self.loss to the class object CtdetLoss, from CtdetTrainer\n",
    "\n",
    "The class definition is given below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Centernet_model(nt.NeuralNetwork,CtdetTrainer):\n",
    "    def __init__(self,opt,model,optimizer=None):\n",
    "        nt.NeuralNetwork.__init__(self)\n",
    "        CtdetTrainer.__init__(self,opt,model,optimizer=None)\n",
    "        self.model=model\n",
    "        self.opt=opt\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    def criterion(self, y, d):\n",
    "        return self.loss(y,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantage of using this modified structure, is to continue using the Experiment class functionalities from nntools.py. An Illustration is provided below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Centernet_model(opt,model)\n",
    "net = net.to(device)\n",
    "adam = torch.optim.Adam(net.parameters(), lr=opt.lr)\n",
    "stats_manager = nt.StatsManager()\n",
    "exp2 = nt.Experiment(net,dataset,valset,adam,stats_manager,\n",
    "output_dir=\"olalalaeo\", batch_size=opt.batch_size,perform_validation_during_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the loss claculation for Centernet, the loss returning step in the run() definition of experiment has to be modified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2(self, num_epochs, plot=None):\n",
    "        \n",
    "        \n",
    "        #  Everything same as run() till this step #\n",
    "        \n",
    "        \n",
    "        \n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            s = time.time()\n",
    "            self.stats_manager.init()\n",
    "            \n",
    "            # Modification made here\n",
    "            for x, d in enumerate(self.train_loader): # Modified\n",
    "                for k in d:\n",
    "                    if k != 'meta':\n",
    "                        d[k] = d[k].to(device=self.net.device, non_blocking=True)\n",
    "                self.optimizer.zero_grad()\n",
    "                y = self.net.forward(d['input'])\n",
    "                loss, _ = self.net.criterion(y, d) # Modified\n",
    "                loss=loss.mean() # Modified\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                with torch.no_grad():\n",
    "                    self.stats_manager.accumulate(loss.item(), x, y, d)\n",
    "            if not self.perform_validation_during_training:\n",
    "                self.history.append(self.stats_manager.summarize())\n",
    "            else:\n",
    "                self.history.append(\n",
    "                    (self.stats_manager.summarize(), self.evaluate()))\n",
    "            print(\"Epoch {} (Time: {:.2f}s)\".format(\n",
    "                self.epoch, time.time() - s))\n",
    "            self.save()\n",
    "            if plot is not None:\n",
    "                plot(self)\n",
    "        print(\"Finish training for {} epochs\".format(num_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above changes are made to reflect the fact that the train_loader sets the inputs as a dictionarya and only relevant keys have to be passed to the loss calculation block, not the entire dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
